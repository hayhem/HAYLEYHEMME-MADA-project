---
title: Project Review Template 
author: Kailin (Kai) Chen
date: "`r file.mtime(knitr::current_input())`"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---
# Overview

**Title of Project**: "Spatial Investigation and Exploration of Factors influencing HIV-related Mortality"

**Name of Project Author(s)**: Hayley Hemme

**Name of Project Reviewer**: Kailin (Kai) Chen

# Specific Project Content Evaluation

## Background, Context, and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments
Project context is well-described with a comprehensive background that includes summary of existing literature. It is well-placed in the context of existing literature and clearly hopes to provide an assessment of spatial correlation between Black-to-White HIV-related mortality rate and social determinants of health and HIV-related outcomes.

### Summary Assessment
*   Strong contextualization and motivation

## Question Description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?

### Feedback and Comments
The questions and hypotheses for this project are clear, and it is also clear how the questions relate to the data.

### Summary Assessment
*   Question/hypotheses fully clear

## Data Description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments
The data is described very well with multiple sources, most of them containing direct links. No other meta-information appears to be available.

### Summary Assessment
*   Source and overall structure of data well explained

## Data Wrangling and Exploratory Analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments
Overall, the data wrangling procedure was straightforward. Data cleaning and processing steps were reasonable and well-explained, and the data itself was cleaned well. Meaningful exploratory results were shown in the manuscript.

### Summary Assessment
*   Essentially no weaknesses in wrangling and exploratory component

## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments
Analysis was done properly, and analysis methods were appropriate for data. Different components of the analysis were done in a suitable manner and well-explained. 

### Summary Assessment
*   Strong and reasonable analysis

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments
Results are presented well, with tables and figures of publication-level quality.

### Summary Assessment
*   Results are very well presented

## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments
This section is missing.

### Summary Assessment
*   Major parts of discussion missing or wrong 

## Further Comments
I was very impressed with the quality of the earlier sections of your manuscript. Please work on Discussion/Conclusion.

# Overall Project Content Evaluation

## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments
The project is well-structured overall, with pertinent files in appropriately-labeled folders that indicate workflow.

### Summary Assessment
*   Well structured

## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

Across the different files for this analysis, the project is well-documented, and I was able to understand the majority of steps for the analysis.

### Summary Assessment
*   Fully and well documented

## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments

Portions of `1_EDA_alt.Rmd`, `2_pca_alt.rmd`, and `3_model_alt.Rmd` are not reproducible without manual intervention due to the same type of coding error.

### Summary Assessment
*   Small parts not reproducible or required manual intervention 

## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

The study overall had a high level of thoroughness, with multiple statistical models being considered. Questions and hypotheses were thoroughly addressed.

### Summary Assessment
*   Strong level of thoroughness

## Further Comments
A good way to check reproducibility is to completely clear the environment and run all qmd files in the way you intend them to be run.